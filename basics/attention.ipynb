{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9217a6f2-0fa8-41e7-9a66-efac4fca4d2f",
   "metadata": {},
   "source": [
    "In this example, we start by loading a pre-trained tokenizer and model from the Transformers library. We then define a sentence and tokenize it using the tokenizer. The resulting inputs object is a PyTorch tensor that can be passed through the model.\n",
    "\n",
    "We pass the inputs through the model to get the hidden states for each token in the sentence. We then get the last hidden state and define a query vector as before.\n",
    "\n",
    "We calculate attention weights and apply attention as before, resulting in a set of attended inputs. However, since the input sequence is now a sentence, the attended inputs are also sequences of tokens.\n",
    "\n",
    "To convert the attended inputs back to text, we use the tokenizer's convert_ids_to_tokens() method to convert the token IDs back to their corresponding text representations. The resulting attended_tokens variable contains the tokens in the sentence that the attention mechanism deemed most important for the task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d412b-bd7f-4d23-9d01-883fba13eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load a pre-trained tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define a sentence\n",
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Tokenize the sentence\n",
    "inputs = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "# Pass the inputs through the model to get hidden states\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Get the last hidden state and apply attention\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "query = torch.randn(1, last_hidden_state.shape[-1])\n",
    "attention_weights = F.softmax(torch.bmm(last_hidden_state, query.unsqueeze(2)).squeeze(2), dim=1)\n",
    "attended_inputs = torch.bmm(last_hidden_state.transpose(1, 2), attention_weights.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "# Convert attended inputs back to text\n",
    "attended_tokens = tokenizer.convert_ids_to_tokens(attended_inputs.argmax(dim=-1).tolist()[0])\n",
    "\n",
    "print('Input sentence:', sentence)\n",
    "print('Attended tokens:', attended_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
